\documentclass{article}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{biblatex}
\addbibresource{bibliografia.bib}

\title{Implementazione di una Convolutional Neural Network (CNN) con TensorFlow e CUDA}
\author{%
  Giuseppe Dimonte MAT 367431 \texttt{giuseppe.dimonte@studenti.unipr.it}
}

\date{}

\begin{document}

\maketitle

\section{Introduzione}
Il Parallel Computing è diventato una risorsa essenziale per affrontare problemi computazionali complessi in tempi accettabili. Nell'ambito dell'elaborazione di grandi dataset e nell'addestramento di modelli di machine learning su di essi, l'utilizzo di tecniche di calcolo parallelo può portare a significativi miglioramenti delle prestazioni e dell'efficienza. In questo contesto, questo progetto si propone di esplorare l'implementazione di una Convolutional Neural Network (CNN) per la classificazione di immagini utilizzando il framework TensorFlow, parallelizzando l'addestramento della rete neurale per sfruttare le potenzialità delle unità di elaborazione grafica (GPU) attraverso CUDA.

\section{Architettura della CNN}
La CNN è stata progettata con l'obiettivo di utilizzare al meglio le capacità di calcolo parallelo delle GPU. L'architettura della CNN comprende due strati convoluzionali seguiti da strati di max pooling e due strati completamente connessi. L'implementazione è stata realizzata utilizzando il framework TensorFlow, che offre supporto per il calcolo parallelo su GPU attraverso CUDA.

La Convolutional Neural Network (CNN) è stata progettata per la classificazione di immagini, con un'architettura che comprende diversi strati per l'estrazione delle caratteristiche e la classificazione finale. Qui di seguito viene fornita una descrizione dettagliata di ciascun strato:

\begin{enumerate}
    \item \textbf{Strato convoluzionale 1:}
    \begin{itemize}
        \item Numero di filtri: 32
        \item Dimensione del filtro: 3x3
        \item Funzione di attivazione: ReLU (Rectified Linear Unit)
        \item Padding: Same (aggiunta di zero ai bordi per mantenere le dimensioni dell'input)
        \item Stride: 1 (passo della convoluzione)
    \end{itemize}
    
    \item \textbf{Strato di pooling 1:}
    \begin{itemize}
        \item Tipo di pooling: Max pooling
        \item Dimensione del pool: 2x2
        \item Stride: 2 (spostamento del pool)
    \end{itemize}
    
    \item \textbf{Strato convoluzionale 2:}
    \begin{itemize}
        \item Numero di filtri: 64
        \item Dimensione del filtro: 3x3
        \item Funzione di attivazione: ReLU
        \item Padding: Same
        \item Stride: 1
    \end{itemize}
    
    \item \textbf{Strato di pooling 2:}
    \begin{itemize}
        \item Tipo di pooling: Max pooling
        \item Dimensione del pool: 2x2
        \item Stride: 2
    \end{itemize}
    
    \item \textbf{Strato completamente connesso 1:}
    \begin{itemize}
        \item Numero di unità nascoste: 128
        \item Funzione di attivazione: ReLU
    \end{itemize}
    
    \item \textbf{Strato completamente connesso 2 (output):}
    \begin{itemize}
        \item Numero di unità: Numero di classi nel dataset
        \item Funzione di attivazione: Softmax (per la classificazione multiclasse)
    \end{itemize}
\end{enumerate}

Questa architettura è stata progettata per l'addestramento efficiente e parallelo su GPU, sfruttando al massimo le capacità di calcolo parallelo offerte da CUDA. Durante l'addestramento della CNN, verranno ottimizzati i pesi dei filtri convoluzionali e dei parametri dei layer completamente connessi per massimizzare le prestazioni del modello di classificazione di immagini.
\begin{lstlisting}[language=Python, basicstyle=\small]
import tensorflow as tf
from tensorflow.keras import layers, models

def create_cnn(input_shape, num_classes):
    model = models.Sequential()

    # Strato convoluzionale 1
    model.add(layers.Conv2D(32, (3, 3), activation='relu', 
    padding='same', input_shape=input_shape))
    model.add(layers.MaxPooling2D((2, 2)))

    # Strato convoluzionale 2
    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))

    # Strato completamente connesso 1
    model.add(layers.Flatten())
    model.add(layers.Dense(128, activation='relu'))

    # Strato completamente connesso 2 (output)
    model.add(layers.Dense(num_classes, activation='softmax'))

    return model

# Parametri della CNN
input_shape = (32, 32, 3)
num_classes = 10

# Creazione della CNN
cnn_model = create_cnn(input_shape, num_classes)
\end{lstlisting}

La CNN è composta da due strati convoluzionali seguiti da strati di max pooling e due strati completamente connessi. La funzione di attivazione utilizzata è ReLU nei livelli convoluzionali e nei livelli completamente connessi, tranne nell'ultimo strato che utilizza la funzione di attivazione Softmax per la classificazione multiclasse.

\section{Addestramento e Valutazione}
La CNN verrà addestrata sul dataset CIFAR-10, un dataset ampiamente utilizzato per la classificazione di immagini. Successivamente, verranno valutate le prestazioni della CNN in termini di accuratezza di classificazione, confrontando le prestazioni dell'addestramento parallelo su GPU con quelle dell'addestramento seriale.

\subsection{Caricamento e Preprocessamento del Dataset}
Abbiamo utilizzato la funzione \texttt{cifar10.load\_data()} fornita da TensorFlow per caricare il dataset CIFAR-10. Le immagini sono state normalizzate dividendo ciascun valore di pixel per 255, in modo che si trovino nell'intervallo [0, 1]. Le etichette sono state convertite in forma one-hot encoding utilizzando la funzione \texttt{to\_categorical()} di TensorFlow.

\subsection{Addestramento della CNN}
Abbiamo definito una CNN utilizzando TensorFlow e l'abbiamo addestrata utilizzando il metodo \texttt{fit()}. La CNN è stata compilata con l'ottimizzatore Adam e la funzione di perdita categorical crossentropy. L'addestramento è stato eseguito per 10 epoche con una dimensione di batch di 64.

\subsection{Valutazione delle Prestazioni}
Dopo l'addestramento, abbiamo valutato le prestazioni della CNN sul set di test utilizzando il metodo \texttt{evaluate()}. Abbiamo calcolato l'accuratezza del modello sul set di test e l'abbiamo stampata a schermo.

\section{File cifar10\_cnn\_training.py}
Di seguito è riportato il codice Python utilizzato per addestrare la CNN sul dataset CIFAR-10:

\begin{lstlisting}[language=Python, caption={Addestramento di una CNN su CIFAR-10}]
import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# Caricamento e preprocessamento del dataset CIFAR-10
(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()
train_images = train_images.astype('float32') / 255.0
test_images = test_images.astype('float32') / 255.0
train_labels = to_categorical(train_labels, num_classes)
test_labels = to_categorical(test_labels, num_classes)

# Stampa le dimensioni del dataset CIFAR-10
print("Dimensioni delle immagini di addestramento:", train_images.shape)
print("Dimensioni delle etichette di addestramento:", train_labels.shape)
print("Dimensioni delle immagini di test:", test_images.shape)
print("Dimensioni delle etichette di test:", test_labels.shape)

# Stampa le prime 5 etichette di addestramento
print("Prime 5 etichette di addestramento:", train_labels[:5])

# Stampa le prime 5 immagini di addestramento
plt.figure(figsize=(10, 10))
for i in range(5):
    plt.subplot(1, 5, i+1)
    plt.imshow(train_images[i])
    plt.axis('off')
plt.show()

# Addestramento della CNN
cnn_model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

history = cnn_model.fit(train_images, train_labels, epochs=10, 
batch_size=64, validation_data=(test_images, test_labels))

# Valutazione delle prestazioni
test_loss, test_acc = cnn_model.evaluate(test_images, test_labels)
print('Test accuracy:', test_acc)

\end{lstlisting}

\subsection{Dataset CIFAR-10}
Il dataset CIFAR-10 è composto da 60.000 immagini a colori di dimensione $32 \times 32$ divise in 10 classi. Quando carichi il dataset utilizzando TensorFlow/Keras, ottieni quattro array NumPy:

\begin{itemize}
    \item \textbf{train\_images}: un array di forma $(50000, 32, 32, 3)$ contenente le immagini di addestramento. Le prime dimensioni $(50000)$ indicano il numero totale di immagini di addestramento, mentre le dimensioni $(32, 32, 3)$ indicano rispettivamente l'altezza, la larghezza e i canali di colore (RGB) di ciascuna immagine.
    
    \item \textbf{train\_labels}: un array di forma $(50000, )$ contenente le etichette di addestramento per le immagini corrispondenti. Ogni etichetta è un numero intero compreso tra 0 e 9, che rappresenta una delle 10 classi del dataset.
    
    \item \textbf{test\_images}: un array di forma $(10000, 32, 32, 3)$ contenente le immagini di test. Ha la stessa struttura di \textit{train\_images}, ma contiene immagini separate utilizzate per valutare le prestazioni del modello dopo l'addestramento.
    
    \item \textbf{test\_labels}: un array di forma $(10000, )$ contenente le etichette di test per le immagini corrispondenti. Ha la stessa struttura di \textit{train\_labels}, ma contiene le etichette per le immagini di test.
\end{itemize}

\section{Introduzione a CUDA}

CUDA, acronimo di Compute Unified Device Architecture, è una piattaforma di calcolo parallelo sviluppata da NVIDIA. È progettato per consentire agli sviluppatori di sfruttare la potenza di calcolo delle unità di elaborazione grafica (GPU) NVIDIA per applicazioni di calcolo ad alte prestazioni (HPC), inclusi compiti di machine learning e deep learning.

Le GPU sono particolarmente adatte per il calcolo parallelo grazie alla loro architettura altamente parallela, che consente loro di elaborare più operazioni contemporaneamente su grandi set di dati. CUDA fornisce un'interfaccia di programmazione che consente agli sviluppatori di scrivere codice parallelo che può essere eseguito efficacemente su GPU NVIDIA.

\subsection{Parallelizzazione dell'addestramento con CUDA}

Stiamo per parallelizzare l'addestramento di una rete neurale utilizzando TensorFlow e sfruttando le potenzialità delle GPU attraverso CUDA. Questo ci permetterà di accelerare notevolmente il processo di addestramento, consentendo alla rete neurale di elaborare più dati contemporaneamente sfruttando le capacità parallele delle GPU.

Utilizzeremo TensorFlow insieme a CUDA per distribuire l'addestramento della rete neurale su più GPU. Ciò ci permetterà di sfruttare appieno le risorse di calcolo parallelo offerte dalle GPU NVIDIA, migliorando significativamente le prestazioni complessive del processo di addestramento.

Parallelizzare l'addestramento della rete neurale per sfruttare le potenzialità delle unità di elaborazione grafica (GPU) attraverso CUDA può essere un'ottima idea per accelerare notevolmente il processo di addestramento. CUDA è una piattaforma di calcolo parallelo sviluppata da NVIDIA per l'utilizzo delle GPU per applicazioni di calcolo ad alte prestazioni.

\subsubsection{Installazione di CUDA e cuDNN}

Prima di tutto, è necessario installare CUDA e cuDNN . CUDA è il toolkit di calcolo parallelo di NVIDIA, mentre cuDNN è una libreria di deep learning ottimizzata per accelerare le prestazioni su GPU NVIDIA. In appendice~\ref{appendix:installazione-nvidia} le istruzioni di installazione fornite da NVIDIA per configurare correttamente CUDA e cuDNN.

\subsubsection{Configurazione di TensorFlow per l'utilizzo di GPU}

Una volta installati CUDA e cuDNN, è importante configurare TensorFlow per l'utilizzo delle GPU. Bisogna Assicurarsi di avere una versione di TensorFlow compatibile con CUDA e cuDNN installati sul proprio sistema. Verifica che TensorFlow riconosca correttamente la presenza della GPU e che sia configurato per utilizzarla quando disponibile.
 Parallelizzare l'addestramento della rete neurale utilizzando CUDA in un file Python chiamato cifar10\_cnn\_training\_parallel.py:
 \begin{lstlisting}[language=Python, caption={l'addestramento della rete neurale utilizzando CUDA in un file Python}]
 import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical

# Caricamento e preprocessamento del dataset CIFAR-10
(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()
train_images = train_images.astype('float32') / 255.0
test_images = test_images.astype('float32') / 255.0
train_labels = to_categorical(train_labels, num_classes)
test_labels = to_categorical(test_labels, num_classes)

# Definizione della strategia per l'addestramento su GPU
strategy = tf.distribute.MirroredStrategy()

# Creazione del modello all'interno del contesto della strategia
with strategy.scope():
    model = create_cnn(input_shape, num_classes)

    # Compilazione del modello
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

# Addestramento del modello all'interno del contesto della strategia
history = model.fit(train_images, train_labels, epochs=10, batch_size=64,
validation_data=(test_images, test_labels))

 \end{lstlisting}

\subsubsection{Utilizzo di tf.distribute.Strategy}

TensorFlow fornisce tf.distribute.Strategy, una API per distribuire l'addestramento su più dispositivi, inclusi i processori grafici. Puoi utilizzare questa API per parallelizzare l'addestramento della tua rete neurale su GPU.

Nell'esempio fornito, tf.distribute.MirroredStrategy() viene utilizzato per distribuire l'addestramento su più GPU. Il modello viene creato all'interno del contesto della strategia, garantendo che venga replicato su tutte le GPU disponibili. L'addestramento del modello avviene all'interno del contesto della strategia, consentendo l'uso parallelo di tutte le GPU disponibili.

\section{Valutazione delle prestazioni del modello}

Una volta completato l'addestramento del modello, è essenziale valutarne le prestazioni utilizzando un insieme di dati di test indipendente. Questo ci permette di comprendere quanto bene il modello generalizzi rispetto ai dati non visti e di identificare eventuali aree di miglioramento. Di seguito sono elencati i passaggi per valutare le prestazioni del modello:

\begin{enumerate}
    \item \textbf{Utilizzo del set di test}: Utilizziamo il set di test precedentemente caricato, composto da \texttt{test\_images} e \texttt{test\_labels}, per valutare il modello addestrato.
    
    \item \textbf{Calcolo delle metriche di valutazione}: Calcola diverse metriche di valutazione per comprendere le prestazioni del modello. Queste metriche possono includere:
        \begin{itemize}
            \item Accuratezza: la percentuale di previsioni corrette rispetto al numero totale di previsioni.
            \item Precisione: la percentuale di previsioni positive correttamente classificate come positive.
            \item Richiamo: la percentuale di veri positivi correttamente identificati rispetto al numero totale di veri positivi.
            \item F1-score: la media armonica tra precisione e richiamo, che fornisce una valutazione bilanciata delle prestazioni del modello.
        \end{itemize}
    
    \item \textbf{Esame dei pattern e degli errori comuni}: Durante la fase di valutazione, esamina attentamente eventuali pattern o errori comuni commessi dal modello. Questo può aiutarti a identificare eventuali debolezze nel modello e a suggerire possibili aree di miglioramento.
\end{enumerate}

Registriamo i risultati della valutazione per considerare eventuali passaggi successivi in base ai risultati ottenuti.

\begin{lstlisting}[language=Python, caption={Valutazione delle prestazioni del modello}]
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Utilizzo del modello per fare previsioni sul set di test
predictions = model.predict(test_images)

# Calcolo dell'accuratezza del modello
accuracy = accuracy_score(test_labels, np.argmax(predictions, axis=1))

# Calcolo della precisione, del richiamo e della F1-score
precision = precision_score(test_labels, np.argmax(predictions, axis=1), average='weighted')
recall = recall_score(test_labels, np.argmax(predictions, axis=1), average='weighted')
f1 = f1_score(test_labels, np.argmax(predictions, axis=1), average='weighted')

# Esame dei pattern e degli errori comuni
conf_matrix = confusion_matrix(test_labels, np.argmax(predictions, axis=1))

# Scrivi i risultati su un file esterno
with open('model_evaluation_results.txt', 'w') as file:
    file.write("Accuratezza del modello: {}\n".format(accuracy))
    file.write("Precisione del modello: {}\n".format(precision))
    file.write("Richiamo del modello: {}\n".format(recall))
    file.write("F1-score del modello: {}\n\n".format(f1))
    file.write("Matrice di confusione:\n")
    np.savetxt(file, conf_matrix, fmt='%d')
\end{lstlisting}

\subsection{Regolarizzazione del modello}

La regolarizzazione è una tecnica utilizzata per prevenire il sovradattamento (overfitting) dei modelli di machine learning. Essa consiste nell'applicare penalità aggiuntive sui pesi del modello durante l'addestramento, al fine di limitarne la complessità e promuovere una migliore generalizzazione sui dati di test.

\subsubsection{Dropout}

Una delle tecniche più comuni di regolarizzazione è il dropout, che consiste nel disattivare casualmente un insieme di unità durante l'addestramento di una rete neurale. Questo impedisce al modello di dipendere troppo fortemente da particolari unità o feature durante l'addestramento, riducendo così il rischio di sovradattamento.

\subsubsection{Regolarizzazione L1/L2}

La regolarizzazione L1 e L2 sono tecniche che aggiungono una penalità proporzionale alla norma dei pesi del modello durante l'addestramento. La regolarizzazione L1 aggiunge una penalità proporzionale alla somma degli valori assoluti dei pesi, mentre la regolarizzazione L2 aggiunge una penalità proporzionale alla somma dei quadrati dei pesi. Queste penalità aiutano a ridurre la complessità del modello e a prevenire il sovradattamento.

\subsubsection{Sperimentazione con valori di regolarizzazione}

Durante lo sviluppo del modello, è importante sperimentare con diversi valori di parametri di regolarizzazione per trovare un equilibrio ottimale tra varianza e bias nel modello. Ciò può comportare l'aggiustamento dei coefficienti di regolarizzazione o l'esplorazione di diverse tecniche di regolarizzazione per trovare la combinazione ottimale che massimizza le prestazioni del modello su dati non visti.

\subsection{Regolazione del modello in Python}

Per regolare il modello utilizzando tecniche come il dropout e la regolarizzazione L1/L2 in Python, puoi utilizzare le funzionalità fornite da TensorFlow/Keras.

\subsubsection{Dropout}

Il dropout è una tecnica di regolarizzazione comunemente utilizzata per prevenire il sovradattamento nei modelli di deep learning. Puoi applicare il dropout tra i livelli della tua rete neurale utilizzando la classe \texttt{Dropout} di Keras. Ecco un esempio di come aggiungere uno strato di dropout al tuo modello:

\begin{verbatim}
from tensorflow.keras import layers, models

# Creazione del modello
model = models.Sequential()

# Aggiunta di uno strato convoluzionale
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))

# Aggiunta dello strato di dropout
model.add(layers.Dropout(0.5))

\end{verbatim}

Nell'esempio sopra, viene aggiunto uno strato di dropout con una frazione del 50\% delle unità da disattivare durante l'addestramento.

\subsubsection{Regolarizzazione L1/L2}

La regolarizzazione L1 e L2 sono tecniche utilizzate per ridurre il sovradattamento nei modelli di machine learning. Puoi applicare la regolarizzazione L1 o L2 ai pesi dei livelli del tuo modello utilizzando i parametri \texttt{kernel\_regularizer} o \texttt{bias\_regularizer} dei livelli di Keras. Ecco un esempio di come aggiungere regolarizzazione L2 a uno strato completamente connesso:

\begin{verbatim}
from tensorflow.keras import layers, models, regularizers

# Creazione del modello
model = models.Sequential()

# Aggiunta di uno strato completamente connesso con regolarizzazione L2
model.add(layers.Dense(128, activation='relu', 
                        kernel_regularizer=regularizers.l2(0.01)))

\end{verbatim}

Nell'esempio sopra, viene aggiunto uno strato completamente connesso con regolarizzazione L2 e un parametro di regolarizzazione pari a 0.01.

\section{Possibili sviluppi}

\subsection{Confronto con altri modelli}

Confrontare le prestazioni del  modello con altri modelli di riferimento o con diverse architetture di reti neurali per determinare quale funziona meglio per il un problema specifico. Esaminare le differenze nelle prestazioni, la complessità computazionale e altri fattori rilevanti per prendere una decisione informata sulla scelta del modello.

\subsection{Analisi degli errori}

Esaminare gli errori commessi dal modello durante la fase di valutazione per identificare eventuali pattern o aree in cui il modello ha difficoltà. Utilizzare tecniche di visualizzazione e analisi per comprendere meglio il comportamento del modello e identificare eventuali aree di miglioramento.

\subsection{Deploy del modello}

Una volta soddisfatto delle prestazioni del modello sarebbe possibile integralo in un'applicazione o in un sistema più ampio per l'uso in produzione. Convertire il modello in un formato compatibile con la piattaforma di destinazione e integralo con altri componenti del sistema. Testare attentamente il modello in un ambiente di produzione e monitora le sue prestazioni nel tempo.

\subsection{Monitoraggio delle prestazioni in produzione}

Monitorare regolarmente le prestazioni del modello in produzione per garantire che mantenga elevate prestazioni nel tempo. Raccogliere dati sulle prestazioni del modello e apportare eventuali aggiornamenti o miglioramenti in base all'evoluzione dei dati o dei requisiti dell'applicazione.

Questi passaggi, massimizzerebbero l'efficacia del modello rendendolo più efficace per risolvere problemi specifici.


\section{Conclusioni}
Attraverso questo progetto, ci aspettiamo di dimostrare l'efficacia dell'utilizzo del Parallel Computing nell'addestramento di reti neurali profonde per la classificazione di immagini, sfruttando le potenzialità delle GPU attraverso CUDA. L'obiettivo è quello di fornire una prova di concetto dell'implementazione di tecniche di calcolo parallelo utilizzando TensorFlow e CUDA, aprendo la strada a futuri sviluppi nell'ottimizzazione delle prestazioni dei modelli di machine learning e deep learning su larga scala.
\newpage
\appendix
\section{Installazione di TensorFlow e Introduzione a Keras}

\subsection{Installazione di TensorFlow}
TensorFlow è una libreria open-source per il machine learning sviluppata da Google. È ampiamente utilizzata per la costruzione e l'addestramento di reti neurali. Di seguito sono riportati i passaggi per installare TensorFlow sul tuo sistema:

\begin{enumerate}
    \item Apri un terminale o una finestra del prompt dei comandi.
    \item Utilizza il gestore di pacchetti Python pip per installare TensorFlow eseguendo il seguente comando:
    
    \begin{verbatim}
    pip install tensorflow
    \end{verbatim}
    
    Questo installerà l'ultima versione stabile di TensorFlow disponibile.
    
    \item Puoi anche installare una versione specifica di TensorFlow specificando il numero di versione desiderato. Ad esempio:
    
    \begin{verbatim}
    pip install tensorflow==2.7.0
    \end{verbatim}
    
    Questo installerà la versione 2.7.0 di TensorFlow.
\end{enumerate}

\subsection{Introduzione a Keras}
Keras è una libreria open-source per il deep learning che fornisce un'interfaccia ad alto livello per la costruzione e l'addestramento di reti neurali. È progettato per essere semplice da usare, modulare e estendibile. Ecco alcune caratteristiche di Keras:

\begin{itemize}
    \item \textbf{Facilità d'uso}: Keras offre una sintassi chiara e intuitiva per la definizione dei modelli neurali.
    \item \textbf{Modularità}: Keras permette di costruire modelli neurali combinando diversi livelli (layer) in modo flessibile.
    \item \textbf{Estensibilità}: Keras è altamente estensibile e consente di personalizzare facilmente i modelli e i livelli secondo le proprie esigenze.
\end{itemize}

Keras è incluso all'interno di TensorFlow come parte del modulo \texttt{tensorflow.keras}, quindi dopo aver installato TensorFlow, avrai accesso a tutte le funzionalità di Keras per lo sviluppo di modelli neurali.


Ecco una possibile spiegazione da aggiungere in appendice riguardo a NumPy e scikit-learn:

\subsection{NumPy e scikit-learn}

\subsubsection{NumPy}

NumPy è una libreria fondamentale per il calcolo scientifico in Python. Fornisce un'implementazione efficiente di strutture dati multidimensionali (ad esempio, array e matrici) e funzioni per operare su di esse. NumPy è ampiamente utilizzato nelle applicazioni di machine learning e deep learning per gestire dati multidimensionali in modo efficiente e per eseguire operazioni matematiche complesse.

Per installare NumPy, è possibile utilizzare il gestore dei pacchetti Python pip eseguendo il seguente comando:

\begin{verbatim}
pip install numpy
\end{verbatim}

\subsubsection{scikit-learn}

scikit-learn è una libreria Python open-source per l'apprendimento automatico (machine learning). Fornisce un'ampia gamma di algoritmi di apprendimento supervisionato e non supervisionato, oltre a strumenti per la preparazione dei dati, la validazione del modello e la valutazione delle prestazioni. scikit-learn è molto utilizzato sia in ambito accademico che industriale per lo sviluppo di modelli di machine learning.

Per installare scikit-learn, è possibile utilizzare il gestore dei pacchetti Python pip eseguendo il seguente comando:

\begin{verbatim}
pip install scikit-learn
\end{verbatim}

\section{Istruzioni di installazione NVIDIA CUDA e cuDNN}
\label{appendix:installazione-nvidia}

Di seguito sono riportate le istruzioni per l'installazione e la configurazione di CUDA e cuDNN fornite da NVIDIA.

\subsection{Installazione di CUDA}
Le istruzioni di installazione di CUDA possono variare a seconda del sistema operativo.
Ecco una guida generale su come installare CUDA:

\begin{enumerate}
    \item \textbf{Verifica dei requisiti di sistema}: Assicurati che il sistema soddisfi i requisiti minimi di CUDA. Puoi trovare informazioni dettagliate sui requisiti di sistema nella documentazione ufficiale di NVIDIA.
    
    \item \textbf{Download del pacchetto di installazione}: Visita il sito web ufficiale di NVIDIA e scarica il pacchetto di installazione di CUDA. Assicurati di selezionare la versione corretta di CUDA compatibile con il proprio sistema operativo e la tua architettura hardware.
    
    \item \textbf{Esecuzione del programma di installazione}: Dopo aver scaricato il pacchetto di installazione, esegui il programma di installazione seguendo le istruzioni fornite. Durante l'installazione, potrebbe essere necessario accettare i termini del contratto di licenza e specificare le opzioni di installazione desiderate, come la directory di installazione e i componenti da installare.
    
    \item \textbf{Configurazione dell'ambiente}: Dopo aver installato CUDA, è necessario configurare l'ambiente del sistema in modo che sia possibile accedere ai file e alle librerie di CUDA. Questo di solito coinvolge l'aggiunta delle directory di installazione di CUDA al percorso di ricerca dell'ambiente e la configurazione di variabili d'ambiente come \texttt{CUDA\_HOME} e \texttt{LD\_LIBRARY\_PATH}.
    
    \item \textbf{Verifica dell'installazione}: Dopo aver completato l'installazione, puoi verificare se CUDA è stato installato correttamente eseguendo alcuni comandi di verifica dalla riga di comando. Ad esempio, puoi eseguire \texttt{nvcc --version} per verificare la versione del compilatore CUDA e \texttt{nvidia-smi} per visualizzare le informazioni sulla tua GPU NVIDIA.
\end{enumerate}

Si prega di visitare il sito ufficiale di NVIDIA per scaricare il pacchetto di installazione e seguire le istruzioni dettagliate fornite nel README e nella documentazione ufficiale \cite{nvidia-installation-guide}.


\subsection{Installazione di cuDNN}
Dopo aver installato CUDA, è possibile scaricare e installare cuDNN seguendo le istruzioni fornite da NVIDIA. Assicurati di scaricare la versione compatibile con la versione di CUDA installata sul tuo sistema.

Una volta installati correttamente CUDA e cuDNN, assicurarsi di configurare TensorFlow per utilizzare le GPU installate sul tuo sistema per l'addestramento della rete neurale.

\printbibliography[heading=subbibliography, title={Bibliografia}] le GPU installate sul proprio sistema per l'addestramento della rete neurale.

\end{document}
